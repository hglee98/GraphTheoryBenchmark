{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from dataset import graph_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(x, N):\n",
    "    v = np.zeros(N)\n",
    "    v[x] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multitask_graph_data(data_path, split, meta_data_path):\n",
    "    data_files = sorted(glob.glob(os.path.join(data_path, split, '*.p')))\n",
    "    path = os.path.join('data_temp/multitask_meta/', meta_data_path, split)\n",
    "    path = str(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path) \n",
    "    for idx, file_name in tqdm(enumerate(data_files)):\n",
    "        npr = np.random.RandomState(seed=idx)\n",
    "        graph_data = pickle.load(open(os.path.join(file_name), \"rb\"))\n",
    "        dense_J = graph_data['J'].todense()\n",
    "        G = nx.from_numpy_array(dense_J)\n",
    "        A = nx.to_numpy_array(G, weight=None)\n",
    "        A = np.array(A)\n",
    "        num_nodes_I = A.shape[0]\n",
    "\n",
    "        # Input feature => size = (|V|, 2)\n",
    "        node_values = npr.uniform(low=0, high=1, size=num_nodes_I)  # i.i.d ~ u(0, 1)\n",
    "        source_node = npr.randint(0, num_nodes_I)  # single source to calculate the shortest path\n",
    "\n",
    "        # target_node_label (the shortest path, eccentricity, graph_laplacian_features) => size = (|V|, 3)\n",
    "        sssp = graph_algorithms.all_pairs_shortest_paths(A, 0)[source_node]\n",
    "        graph_laplacian = graph_algorithms.graph_laplacian_features(A, node_values)\n",
    "        eccentricity = graph_algorithms.eccentricity(A)\n",
    "        labels = [sssp, graph_laplacian, eccentricity]\n",
    "        node_label = np.swapaxes(np.stack(labels), 0, 1)\n",
    "\n",
    "\n",
    "        # target_graph_label (is_connected, diameter, spectral_radius) => size = 3\n",
    "        is_connected = graph_algorithms.is_connected(A)\n",
    "        diameter = graph_algorithms.diameter(A)\n",
    "        spectral_radius = graph_algorithms.spectral_radius(A)\n",
    "        labels = [is_connected, diameter, spectral_radius]\n",
    "        graph_labels = np.asarray(labels).flatten()\n",
    "\n",
    "        # concatenation between one hot vector which represents source node and i.i.d node values\n",
    "        features = np.stack([to_categorical(source_node, num_nodes_I), node_values], axis=1)\n",
    "\n",
    "        # variables from numpy to Pytorch tensor\n",
    "        features = torch.from_numpy(np.asarray(features)).float()\n",
    "        node_labels = torch.from_numpy(np.asarray(node_label)).float()\n",
    "        graph_labels = torch.from_numpy(np.asarray(graph_labels)).float()\n",
    "        edge_index = torch.tensor(graph_data['msg_node']).t().contiguous().long()\n",
    "        data = Data(x=features, edge_index=edge_index, y=(node_labels, graph_labels), adj=A, graph=G)\n",
    "        torch.save(data,\n",
    "                   os.path.join('data_temp/multitask_meta/', meta_data_path, split,\n",
    "                   f'{meta_data_path}_{idx}.pt'))\n",
    "        \n",
    "def generate_multitask_graph_testset(root):\n",
    "    data_files = sorted(glob.glob(os.path.join(root, '*.p')))\n",
    "\n",
    "    for idx, file_name in tqdm(enumerate(data_files)):\n",
    "        npr = np.random.RandomState(seed=idx+43212)\n",
    "        graph_data = pickle.load(open(file_name, \"rb\"))\n",
    "        dense_J = graph_data['J'].todense()\n",
    "        G = nx.from_numpy_array(dense_J)\n",
    "        A = nx.to_numpy_array(G, weight=None)\n",
    "        A = np.array(A)\n",
    "        num_nodes_I = A.shape[0]\n",
    "\n",
    "        # Input feature => size = (|V|, 2)\n",
    "        node_values = npr.uniform(low=0, high=1, size=num_nodes_I)  # i.i.d ~ u(0, 1)\n",
    "        source_node = npr.randint(0, num_nodes_I)  # single source to calculate the shortest path\n",
    "\n",
    "        # target_node_label (the shortest path, eccentricity, graph_laplacian_features) => size = (|V|, 3)\n",
    "        sssp = graph_algorithms.all_pairs_shortest_paths(A, 0)[source_node]\n",
    "        graph_laplacian = graph_algorithms.graph_laplacian_features(A, node_values)\n",
    "        eccentricity = graph_algorithms.eccentricity(A)\n",
    "        labels = [sssp, graph_laplacian, eccentricity]\n",
    "        node_label = np.swapaxes(np.stack(labels), 0, 1)\n",
    "\n",
    "        # target_graph_label (is_connected, diameter, spectral_radius) => size = 3\n",
    "        is_connected = graph_algorithms.is_connected(A)\n",
    "        diameter = graph_algorithms.diameter(A)\n",
    "        spectral_radius = graph_algorithms.spectral_radius(A)\n",
    "        labels = [is_connected, diameter, spectral_radius]\n",
    "        graph_labels = np.asarray(labels).flatten()\n",
    "\n",
    "        # concatenation between one hot vector which represents source node and i.i.d node values\n",
    "        features = np.stack([to_categorical(source_node, num_nodes_I), node_values], axis=1)\n",
    "\n",
    "        # variables from numpy to Pytorch tensor\n",
    "        features = torch.from_numpy(np.asarray(features)).float()\n",
    "        node_labels = torch.from_numpy(np.asarray(node_label)).float()\n",
    "        graph_labels = torch.from_numpy(np.asarray(graph_labels)).float()\n",
    "        edge_index = torch.tensor(graph_data['msg_node']).t().contiguous().long()\n",
    "        data = Data(x=features, edge_index=edge_index, y=(node_labels, graph_labels), adj=A, graph=G\n",
    "                    , name=graph_data['name'])\n",
    "        torch.save(data,\n",
    "                   os.path.join('data_temp/multitask/test',\n",
    "                   f'data_{idx}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:02,  4.26s/it]"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "path = ['data/exp2_train_100_0.3_meta/meta_group_1',\n",
    "        'data/exp2_train_100_0.3_meta/meta_group_2',\n",
    "        'data/exp2_train_100_0.3_meta/meta_group_3',\n",
    "        'data/exp2_train_100_0.3_meta/meta_group_4',\n",
    "        'data/exp2_train_100_0.3_meta/meta_group_5']\n",
    "def generation(data_path):\n",
    "    meta_data_path = data_path.split('/')[-1]\n",
    "    generate_multitask_graph_data(data_path, 'train', meta_data_path)\n",
    "    generate_multitask_graph_data(data_path, 'val', meta_data_path)\n",
    "pool_obj = multiprocessing.Pool()\n",
    "pool_obj.map(generation, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}